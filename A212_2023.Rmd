---
title: "A212 Lecturing 2023"
author: "Valentine Chisango"
date: '2023-01-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loss Distributions

```{r loss_distributions, echo=FALSE}

#library containing numerous insurnace datasets
library(insuranceData)

#library for string manipulation
library(stringr)

#setting to avoid defaulting to scientisfic notation
options(scipen=999)

#loading auto claims dataset
data("AutoClaims")

#truncating the dataset
loss_data = AutoClaims$PAID[AutoClaims$PAID <= 10000]

hist(loss_data, xlab = "Claim Amount", ylab = "Frequency", main = "Histogram of Motor Insurance Claims", col = "purple")

#useful values for calculations
sum_xi = sum(loss_data)
sum_xisq = sum(loss_data^2)
median_xi = median(loss_data)
N = length(loss_data)
x_bar = sum_xi/N

useful_data = data.frame(
  SummaryStatistic = c(sum_xi)
)

#estimates of lambda
lambda_mme = 1/x_bar
lambda_mle = 1/x_bar
lambda_mpe = -log(0.5)/median_xi

breaks = seq(from = 0, to = 10000, by = 1000)
intervals = cut(loss_data, breaks = breaks)
observed_counts = as.numeric(table(intervals))

intervals_text <- str_replace_all(levels(intervals), "[()\\[\\]]", "")

interval_ranges <- lapply(intervals_text, function(x) c(as.numeric(strsplit(x, ",")[[1]])))

expected_counts_mme = c()
for (i in 1:length(interval_ranges)){
  expected_counts_mme[i] = length(loss_data)*(pexp(interval_ranges[[i]][2], rate = lambda_mme) - pexp(interval_ranges[[i]][1], rate = lambda_mme))
}

expected_counts_mle = c()
for (i in 1:length(interval_ranges)){
  expected_counts_mle[i] = length(loss_data)*(pexp(interval_ranges[[i]][2], rate = lambda_mle) - pexp(interval_ranges[[i]][1], rate = lambda_mle))
}

expected_counts_mpe = c()
for (i in 1:length(interval_ranges)){
  expected_counts_mpe[i] = length(loss_data)*(pexp(interval_ranges[[i]][2], rate = lambda_mpe) - pexp(interval_ranges[[i]][1], rate = lambda_mpe))
}

test_stat_mle = sum((observed_counts-expected_counts_mle)^2/expected_counts_mle)
test_stat_mme = sum((observed_counts-expected_counts_mme)^2/expected_counts_mme)
test_stat_mpe = sum((observed_counts-expected_counts_mle)^2/expected_counts_mpe)

p_value_mle = pchisq(test_stat_mle, df = length(observed_counts)-2, lower.tail = FALSE)
p_value_mme = pchisq(test_stat_mme, df = length(observed_counts)-2, lower.tail = FALSE)
p_value_mpe = pchisq(test_stat_mpe, df = length(observed_counts)-2, lower.tail = FALSE)

fit_lnorm = fitdistr(loss_data, "log-normal")

shape = fit_lnorm$estimate[1]
scale = fit_lnorm$estimate[2]

expected_counts_wei = c()
for (i in 1:length(interval_ranges)){
  expected_counts_wei[i] = length(loss_data)*(plnorm(interval_ranges[[i]][2], meanlog = shape, sdlog = scale) - plnorm(interval_ranges[[i]][1], meanlog = shape, sdlog = scale))
}

test_stat_lnorm = sum((observed_counts-expected_counts_lnorm)^2/expected_counts_lnorm)
p_value_lnorm = pchisq(test_stat_wei, df = length(observed_counts)-3, lower.tail = FALSE)


#superimposing the fitting distributions onto the observed data
hist(loss_data, xlab = "Claim Amount", main = "Histogram of Motor Insurance Claims", col = "gray", ylim = c(0,0.0007), freq = FALSE)
density_mle = dexp(1:10000, rate = lambda_mle)
lines(density_mle, col = "red", lwd = 2)
density_mme = dexp(1:10000, rate = lambda_mme)
lines(density_mme, col = "green", lwd = 2)
density_mpe = dexp(1:10000, rate = lambda_mpe)
lines(density_mpe, col = "blue", lwd = 2)
density_lnorm = dlnorm(1:10000, meanlog = shape, sdlog = scale)
lines(density_lnorm, col = "orange", lwd = 2)
legend("topright", c("Exp-MME","Exp-MLE","Exp-MPE", "Log-Norm"), col = c("green", "red", "blue", "orange"), lty = 1)
```

## Extreme Value Theory
```{r extreme_value_theory, echo=FALSE}
#library containing numerous insurnace datasets
library(insuranceData)

#library for string manipulation
library(stringr)

#library for fitting more distributions, including the Pareto
library(fitdistrplus)
library(actuar)

#libraries for graph plotting
library(ggplot2)
library(ggbreak) 

#setting to avoid defaulting to scientisfic notation
options(scipen=999)

#loading auto claims dataset
data("AutoClaims")

#truncating the dataset
loss_data = AutoClaims$PAID

fit_pareto1 = fitdist(loss_data, "pareto", start=list(shape=1, scale=1))
shape = fit_pareto1$estimate[1]
scale = fit_pareto1$estimate[2]

p <- ggplot(data.frame(loss_data), aes(x=loss_data)) + 
  geom_histogram(binwidth=5000, fill="#69b3a2", color="#e9ecef", boundary=0)  + xlab("Claim Amount") + ylab("Frequency") +theme_classic() + theme(plot.title=element_text(hjust=0.5)) + scale_y_break(c(500,6000)) + labs(title="Histogram of Motor Insurance Claims")
p
```

## Reinsurance
```{r reinsurance, echo=FALSE}
#library containing numerous insurnace datasets
library(insuranceData)

#library for string manipulation
library(stringr)

#libraries for graph plotting
library(ggplot2)
library(ggbreak) 
library(dplyr)

#setting to avoid defaulting to scientisfic notation
options(scipen=999)

#loading auto claims dataset
data("AutoClaims")

#truncating the dataset
loss_data = AutoClaims$PAID

set.seed(1)

sample_data = sample(loss_data, 10)
#sample_data = sort(sample_data)

values_prop = rbind(sample_data*0.4, sample_data*0.6)
M = 2000
values_xl = rbind(pmin(sample_data, M), pmax(0, sample_data - M))
L = 1000
values_excess = rbind( pmin(sample_data, L), pmax(sample_data - L, 0))
colors = c("#69b3a2","#FF3333")
colors2 = c("#FF3333","#69b3a2")
payer <- c("Insurer","Reinsurer")
payer2 <- c("Policyholder","Insurer")

png(file = "bar_prop.png")
barplot(values_prop, main = "Share of claims under proportional reinsurance", ylab = "Claim Amount", col = colors)
legend("topright", payer, cex = 1.3, fill = colors)
dev.off()

png(file = "bar_xl.png")
barplot(values_xl, main = "Share of claims under excess of loss reinsurance", ylab = "Claim Amount", col = colors)
legend("topright", payer, cex = 1.3, fill = colors)
dev.off()

png(file = "bar_excess.png")
barplot(values_excess, main = "Share of claims under a policy excess", ylab = "Claim Amount", col = colors2)
legend("topright", payer2, cex = 1.3, fill = colors2)
dev.off()

M = 20000

mean(loss_data)
mean(loss_data*0.6)
mean(pmin(sample_data, M))
mean(pmax(sample_data - L, 0))

var(loss_data)
var(loss_data*0.6)
var(pmin(sample_data, M))
var(pmax(sample_data - L, 0))

```
# Makrov Chains
```{r}
#libraries used to draw the transition diagram
library('heemod')
library('diagram')

#library to work with markov chains
library(markovchain)

#setting up the model
states = c('H', 'D')
P = matrix(c(.995, .005,
             .0025, .9975), nrow = 2, ncol = 2, byrow = TRUE)

#drawing the transition diagram
loanhealth_model <- define_transition(
state_names = states,
  .995, .005, 
  .0025, .9975)

plot(loanhealth_model, 
     self.shiftx = c(0.15,0.15,0), 
     self.shifty = c(0.11,-0.11,0), box.col = c('red', 'green'))

#creating a markov chain object
mc = new("markovchain", transitionMatrix = P, states = states, name = "LoanHealth") 

#extracting the properties of the chain
is.irreducible(mc)
period(mc)

#setting up the loan information
loan_amount = 100
repayment = c(10, 0)
prior_dist = c(1,0)
expected_repayment = numeric(12)

#calculating the expected profit
for (i in 1:12){
  new_dist = prior_dist %*% P
  expected_repayment[i] = sum(new_dist * repayment)
  prior_dist = new_dist
}

expected_revenue = sum(expected_repayment)
expected_profit = expected_revenue - loan_amount

#stationary distribution
stationary_dist = steadyStates(mc)
```




